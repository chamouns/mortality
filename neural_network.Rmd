

## Data business

Load some libraries and necessary data files
```{r}
library(tidyverse)
library(tidymodels)
library(feather)
library(magrittr)
library(skimr)
library(vip)
per <- read_feather("data/simulation_data/all_persons.feather")
```

Compute some summary statistic for each client.
```{r}
clients <-
  per %>%
  group_by(client) %>%
  summarize(
    zip3 = first(zip3),
    size = n(),
    volume = sum(FaceAmt),
    avg_qx = mean(qx),
    avg_age = mean(Age),
    per_male = sum(Sex == "Male") / size,
    per_blue_collar = sum(collar == "blue") / size,
    expected = sum(qx * FaceAmt),
    actual_2020 = sum(FaceAmt[year == 2020], na.rm = TRUE),
    ae_2020 = actual_2020 / expected,
    adverse = as_factor(if_else(ae_2020 > 3, "ae > 3", "ae < 3"))
  ) %>%
  relocate(adverse, ae_2020, .after = zip3) %>%
  mutate(adverse = fct_relevel(adverse, c("ae > 3", "ae < 3")))
```

We can add some demographic information based on zip3.
```{r}
zip_data <-
  read_feather("data/data.feather") %>%
  mutate(
    density = POP / AREALAND,
    AREALAND = NULL,
    AREA = NULL,
    HU = NULL,
    vaccinated = NULL,
    per_lib = NULL,
    per_green = NULL,
    per_other = NULL,
    per_rep = NULL,
    unempl_2020 = NULL,
    deaths_covid = NULL,
    deaths_all = NULL
  ) %>%
  rename(
    unemp = unempl_2019,
    hes_uns = hes_unsure,
    str_hes = strong_hes,
    income = Median_Household_Income_2019
  )
```
There seems to be some clients with some zip codes that we cannot deal with. These are the ones
```{r}
clients %>%
  anti_join(zip_data, by = "zip3") %>%
  select(zip3)
```
These correspond to the following areas

ZIP3 | Area       |
-----|------------|
969  | Guam, Palau, Federated States of Micronesia, Northern Mariana Islands, Marshall Islands |
093  | Military bases in Iraq and Afghanistan |
732  | Not in use |
872  | Not in use |
004  | Not in use |
202  | Washington DC, Government 1 |

We ignore clients with these zip codes. There are also two clients in DC for which we're missing election data. We will ignore those as well.
```{r}
clients %<>%
  inner_join(zip_data, by = "zip3") %>%
  drop_na()
```

We now have our full dataset. Behold!
```{r}
skim(clients)
```

# single layer network model 


# Engine
```{r}
sln_spec <-
  mlp() %>%
  set_engine("nnet") %>%
  set_mode("classification")
```

# Recipe 
```{r}
sln_recipe <- 
  recipe(formula = adverse ~ ., data = clients) %>% 
  step_rm(client, zip3, ae_2020, actual_2020 ) %>%
  step_zv(all_predictors()) %>% # remove zero variance columns (in our case it will remove per collar)
  step_normalize(all_predictors(), -all_nominal()) 
```

# Workflow 
```{r}
sln_workflow <- 
  workflow() %>%
  add_model(sln_spec) %>% 
  add_recipe(sln_recipe)
```

# Feed data (train the model)
```{r}
set.seed(4751)
sln_split <- initial_split(clients, prop=0.8, strata= adverse) # it will split data in a way why keeping the proportion of adverse the same (splitting based on the outcome)

# here it directly split then use test and find accuracy, get summary results using collect_metrics
sln_fit <- sln_workflow %>%
  last_fit(sln_split, metrics=metric_set(sens, spec, ppv, npv, bal_accuracy, detection_prevalence))
```

# Getting results 
```{r}
sln_fit %>% 
  collect_metrics()
```


