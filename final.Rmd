```{r, setup, include=FALSE}
knitr::opts_chunk$set(
      fig.width = 5, fig.height = 5, dpi = 300, fig.path = "figures/final-"
)
```

# FINAL PRESENTATION

## Data loading and boring stuff
No need to talk about this.
Please download the latest version of `data/processed_data_20_12_23.feather` from Google Drive.
```{r message = FALSE}
library(tidyverse)
library(tidymodels)
library(probably)
library(themis)
library(feather)
library(magrittr)
library(skimr)
library(vip)
library(ggbeeswarm)
library(finetune)
library(lubridate)
library(glue)
library(slider)
library(tsibble)
library(fable)

weekly_data <-
  read_feather("data/processed_data_20_12_23.feather") %>%
  select(-ae_2021, -ae_2020, -ae_2019,
         -actual_2021, -actual_2020, -actual_2019, -adverse,
         -STATE_NAME, -shrinkage,  -dep_var) 

yearly_data <-
  read_feather("data/processed_data_20_12_23.feather") %>%
  group_by(client) %>%
  slice(1) %>%
  select(-date, -claims, -zip_deaths, -smoothed_ae, -shrunk_ae,
         -class, -smoothed_deaths,
         -hes, -hes_uns, -str_hes, -ae, -dep_var, -shrinkage, -STATE_NAME, -ihme_deaths)
```





# Introduction
AEs changing in 2019, 2020, copy paste from pres2

We explain how we choose the threshold for adverse and not
```{r}
weekly_data %>%
  ungroup() %>%
  group_by(date) %>%
  summarize(
      `12.5` = quantile(shrunk_ae, 0.125),
      `25` = quantile(shrunk_ae, 0.25),
      `50` = quantile(shrunk_ae, 0.50)
  ) %>%
  pivot_longer(-date, names_to = "pth", values_to = "value") %>%
  ggplot(aes(x = date, y = value, color = pth)) +
  geom_line() +
  geom_hline(yintercept = 2.5, linetype = "dashed")
```

How many clients are adverse each week?
```{r}
weekly_data %>%
  group_by(date) %>%
  summarize(prop_adverse = sum(class == "Adverse") / n()) %>%
  ggplot(aes(x = date, y = prop_adverse)) + geom_line()
```
# "Baseline" stuff
Can maybe also copy paste some things from pres 2.

This is trained on known COVID-19 data.

* Why? It can be used as is in a future pandemic.
* Why not? Future pandemics may have different target mortality compared to COVID19.

# Time stuff

* Why? This model is more reactive than the previous one. It's trained on current pandemic data. It can be updated with time.
* Why not? This will be very bad early on in the pandemic (lack of data) and bad when forecasting is hard.

## Boring stuff 

```{r}
train <-
  weekly_data %>%
  filter(date <= "2021-01-01")

test <-
  weekly_data %>%
  filter(date > "2021-01-01" & date <= "2021-06-01")
```


```{r}
forecast <-
  weekly_data %>%
  filter(date >= "2020-03-15" & date <= "2021-01-01") %>%
  as_tsibble(index = date, key = client) %>%
  model(arima = ARIMA(smoothed_deaths)) %>%
  forecast(h = "6 months")
```

```{r}
forecasted_test <-
  forecast %>%
  as_tibble() %>%
  select(client, date, .mean) %>%
  right_join(test, by = c("client", "date")) %>%
  select(-smoothed_deaths) %>%
  rename(smoothed_deaths = .mean)

```


## Model selection
Looking at performance every day for 3 months in the future. 



Creating a common recipe for all models. 

```{r}
common_recipe <-
  recipe(class ~ ., data = weekly_data) %>%
  step_rm(client, zip3, claims, smoothed_ae, shrunk_ae,  ae, zip_deaths, ihme_deaths, date) %>%
  step_zv(all_predictors()) %>%
  step_log(volume, POP) %>%
  step_normalize(all_predictors())
```

```{r}
forest_spec <-
  rand_forest(trees = 1000) %>%
  set_engine("ranger", num.threads = 8, seed = 123456789) %>%
  set_mode("classification")

log_spec <- 
  logistic_reg(
  mode = "classification",
  engine = "glm")

svm_lin_spec <-
  svm_linear() %>%
  set_engine("LiblineaR") %>%
  set_mode("classification")

knn_spec <-
  nearest_neighbor() %>%
  set_engine("kknn") %>%
  set_mode("classification")

sln_spec <-
  mlp(activation = "relu", hidden_units = 6, epochs = 100) %>%
  set_engine("keras", verbose=0) %>%
  set_mode("classification")


bt_spec <- boost_tree(
  mode = "classification",
  engine = "xgboost",
  trees = 100)
```


```{r}
bt_wf <-
  workflow() %>%
  add_recipe(common_recipe) %>%
  add_model(bt_spec)

log_wf <-
  workflow() %>%
  add_recipe(common_recipe) %>%
  add_model(log_spec)

forest_wf <-
  workflow() %>%
  add_recipe(common_recipe) %>%
  add_model(forest_spec)

svm_lin_wf <-
  workflow() %>%
  add_recipe(common_recipe) %>%
  add_model(svm_lin_spec)

knn_wf <-
  workflow() %>%
  add_recipe(common_recipe) %>%
  add_model(knn_spec)

sln_wf <-
  workflow() %>%
  add_recipe(common_recipe) %>%
  add_model(sln_spec)
```


```{r}
wflows <- tribble(~wflow ,
                  sln_wf,
                  knn_wf, log_wf, forest_wf, bt_wf)
 


wflows <-
  wflows %>%
  mutate(wflows_fit = map(wflow, ~ fit(.x, train))) 

wflows <-
  wflows %>%
  mutate(
    class_predict = map(wflows_fit, ~ predict(.x, forecasted_test)),  
    prob_predict = map(wflows_fit, ~ predict(.x, forecasted_test, type = "prob")))
```

```{r}
wflows %>%
  bind_cols(tribble(~id, "sln", "knn", "log", "forest", "bt")) %>%
  select(-wflow, -wflows_fit) %>%
  mutate(prob_predict = map(prob_predict, ~ bind_cols(.x, test %>% select(date, class)))) %>%
  unnest(c(class_predict, prob_predict)) %>%
  group_by(id, date) %>%
  summarize(
            sens = sens_vec(class, .pred_class),
            spec = spec_vec(class, .pred_class),
            roc_auc = roc_auc_vec(class, .pred_Adverse), .groups = "keep") %>%
  pivot_longer(sens:roc_auc, names_to = "metric", values_to = "value") %>%
  ungroup() %>%
  ggplot(aes(x = date, y = value, color = id)) +
  geom_point() +
  geom_line() +
  facet_wrap( ~ metric)

```
```{r}
wflows_cheat <-
  wflows %>%
  mutate(
    class_predict = map(wflows_fit, ~ predict(.x, test)),  
    prob_predict = map(wflows_fit, ~ predict(.x, test, type = "prob")))


wflows_cheat %>%
  bind_cols(tribble(~id, "sln", "knn", "log", "forest", "bt")) %>%
  select(-wflow, -wflows_fit) %>%
  mutate(prob_predict = map(prob_predict, ~ bind_cols(.x, test %>% select(date, class)))) %>%
  unnest(c(class_predict, prob_predict)) %>%
  group_by(id, date) %>%
  summarize(
            sens = sens_vec(class, .pred_class),
            spec = spec_vec(class, .pred_class),
            roc_auc = roc_auc_vec(class, .pred_Adverse), .groups = "keep") %>%
  pivot_longer(sens:roc_auc, names_to = "metric", values_to = "value") %>%
  ungroup() %>%
  ggplot(aes(x = date, y = value, color = id)) +
  geom_point() +
  geom_line() +
  facet_wrap( ~ metric)

```



## Training on part of the data (forecasted smoothed deaths + IHME)
Testing on known clients and unknown clients.

### Case study: June 2020

### Case study: Jan 2021

## Predicting AE as a time-series
with IHME death vs with  zip death vs without death 

Train global model for all clients.

Target: shrunk_ae (AE after shrunk).
Predictors: data before covid-19 (based on the zip code where the company is located (such as poverty, education, unemployment levels) and characteristics of the company (such as the average age of its employees).
Data pre-processing: log(POP), log(volume),log(expected) and normalize all predictors

Split: Train set(2020-03-15 - 2020-12-27), Test set (2021-01-03- 2021-06-27).
Model: random forest, tuned random forest, Radial basis function support vector machines, K-nearest neighbors, Xgboost. 
Outcome: predicting shrunk_ae, confident interval for each client every day.

Performance: 
Plot the predict result for each client, pick several to present, 
The confident interval can cover the exact shrunk_ae

Classify whether the client is adverse or not adverse: shrunk_ae > 2.5.
plot sens, spec,j_index, accuracy
Xgboost has biggest j_index. K-nearest neighbors has good sens, and worst spec while svm has bad sens and good spec.

Calculate the predicted total claim every week and every client for half year.
K-nearest neighbors catch the trend for every week total claim.

Currently, we use the predicting shrunk_ae as predicting result for each model. 
Possible future improvement: 1. use confident interval to find a better predict shrunk_ae 
2. combine different model's results to get final result. 3.Compared the result with weekly death into account, we can add predicted death data as one predictor.
 


## Common data
```{r}
library(tidyverse)
library(tidymodels)
library(modeltime)
library(timetk)
library(probably)
library(themis)
library(feather)
library(magrittr)
library(skimr)
library(vip)
library(dplyr)
library(lubridate)
```



Get weeklydata 
```{r}
clients<-read_feather("data/processed_data_20_12_23.feather")%>%
  select(-ae_2021, -ae_2020, -ae_2019,
         -actual_2021, -actual_2020, -actual_2019, -adverse,
         -STATE_NAME, -dep_var, -smoothed_ae)%>%
  filter(date >= "2020-03-15")%>%
  mutate(client = as.factor(client))%>%
  mutate(POP=log(POP))%>%
  mutate(volume = log(volume))%>%
  mutate(expected = log(expected))
```

Train global model for all clients.

Target: shrunk_ae (AE after shrunk).
Predictors: data before covid-19 (based on the zip code where the company is located (such as poverty, education, unemployment levels) and characteristics of the company (such as the average age of its employees).
Data pre-processing: log(POP), log(volume),log(expected) and normalize all predictors
Split: Train set(2020-03-15 - 2020-12-27), Test set (2021-01-03- 2021-06-27).

split
```{r}
#split
  split
  set.seed = 1234
  splits <-  clients %>% time_series_split(initial = "6 months", assess = "6 months", date_var = date, cumulative = TRUE)
  train = training(splits)
  test = testing(splits)
  #index <- unique(train$client)
  #val <- sliding_index(training(splits), index)
  
  #crossval <- vfold_cv(training(splits), strata = zip3)
```
#window forest
It is not good 
```{r cache= TRUE }
model_spec <- window_reg(
        window_size     = "6 months",
        id = "client"
    ) %>%
    # Extra parameters passed as: set_engine(...)
    set_engine(
        engine          = "window_function",
        #window_function = median,
        na.rm           = TRUE,
        window_function = ~ tail(.x, 100),
    )

# Fit Spec
model_fit <- model_spec %>%
    fit(shrunk_ae~ date + client, data = train)
model_fit
predict(model_fit, test)


model_tbl <- modeltime_table(
    model_fit)

model_tbl %>%
    modeltime_forecast(
        new_data    = testing(splits),
        actual_data = bind_rows(training(splits), testing(splits)),
        conf_by_id  = TRUE
    ) %>%
    group_by(client) %>%
    filter(client == c( "1", "5", "7"))%>%
    plot_modeltime_forecast(
        .facet_ncol  = 3,
        .interactive = FALSE,
        .title = "Forecast Plot",
        .line_alpha = 0.6,
        .line_size = 1,
        .y_intercept = 3.0
    )
calib_tbl <- model_tbl %>%
    modeltime_calibrate(
      new_data = testing(splits), 
      id       = "client"
    )
calib_tbl %>% 
    modeltime_accuracy(acc_by_id = FALSE) %>% 
    table_modeltime_accuracy(.interactive = FALSE)
calib_tbl %>% 
    modeltime_accuracy(acc_by_id = TRUE) %>% 
    table_modeltime_accuracy(.interactive = FALSE)

```

```{r}
result0 <- calib_tbl %>%
    modeltime_forecast(
        new_data    = testing(splits),
        actual_data = bind_rows(training(splits), testing(splits)),
        conf_by_id  = TRUE
    ) 
result0
```
```{r}
predresult0 <- result0 %>%
  select(-.model_desc, -.conf_lo, -.conf_hi, -.key) %>%
  rename(model = .model_id, value = .value, date= .index)%>%
  relocate(model, value, .after = client)%>%
  pivot_wider(names_from = model, values_from =value)%>%
  rename(actual = "NA", windows = "1" )%>%
  drop_na()%>%
  mutate(obs =  ifelse(actual > 2.5, TRUE, FALSE))%>%
  mutate(windows_pred=  ifelse(windows > 2.5,TRUE, FALSE))%>%
  mutate(obs = as.factor(obs), windows_pred = as.factor(windows_pred))

conf0<-predresult0%>%
  group_by(date) %>%
  summarize(sens_windows = sens_vec(obs, windows_pred),
            spec_windows = spec_vec(obs, windows_pred), 
            jinex_window = j_index_vec(obs,windows_pred),
            acc_windows = accuracy_vec(obs, windows_pred))

conf0%>%
  pivot_longer(sens_windows, names_to = "metric", values_to = "value")%>%
  ggplot(aes(x = date, y = value, color = metric)) + geom_line()
  
conf0%>%
  pivot_longer(spec_windows, names_to = "metric", values_to = "value")%>%
  ggplot(aes(x = date, y = value, color = metric)) + geom_line()

conf0%>%
  pivot_longer(jinex_window, names_to = "metric", values_to = "value")%>%
  ggplot(aes(x = date, y = value, color = metric)) + geom_line()

conf0%>%
  pivot_longer(acc_windows, names_to = "metric", values_to = "value")%>%
  ggplot(aes(x = date, y = value, color = metric)) + geom_line()

```



We now gather our recipes and models.
Model: random forest, tuned random forest, Radial basis function support vector machines, K-nearest neighbors, Xgboost. 
Outcome: predicting shrunk_ae, confident interval for each client every day.


#recipe with ihme death data
```{r cache=TRUE}
rec_obj <-
    recipe(shrunk_ae ~ ., data = training(splits)) %>%
    #step_rm(year,month,day)%>%
    step_rm(zip3)%>%
    step_rm( claims , class, shrinkage, ae,zip_deaths, smoothed_deaths)%>%
    #step_rm(adverse)%>%
    step_mutate(client = droplevels(client)) %>%
    step_timeseries_signature(date) %>%
    step_rm(date)%>%
    step_dummy(all_nominal_predictors(), one_hot = TRUE)%>%
     step_zv(all_predictors()) %>%
    step_normalize(all_predictors(), -all_nominal())

summary(prep(rec_obj))
bake(prep(rec_obj),training(splits))
```

#engine
```{r}
forest_spec <-
  rand_forest(trees = 1000) %>%
  set_engine("ranger", num.threads = 8, seed = 123456789) %>%
  #set_mode("classification") %>%
  set_mode("regression")%>%
  set_engine("ranger", num.threads = 8, importance = "impurity", seed = 123)
tuned_forest_spec <-
  rand_forest(trees = 1000, mtry = 12, min_n = 21) %>%
  #set_mode("classification") %>%
  set_mode("regression")%>%
  set_engine("ranger", num.threads = 8, importance = "impurity", seed = 123)
svm_rbf_spec <-
  svm_rbf() %>%
  set_engine("kernlab") %>%
  #set_mode("classification")
  set_mode("regression")
knn_spec <-
  nearest_neighbor() %>%
  set_engine("kknn") %>%
  #set_mode("classification")
  set_mode("regression")
xgboost_spec <-
  boost_tree(trees = 100) %>%
  set_engine("xgboost") %>%
  #set_mode("classification")
  set_mode("regression")
```

# workflow with ihme death data
```{r cache= TRUE}
wflw_rf <- workflow() %>%
    add_model(
        forest_spec
    ) %>%
    add_recipe(rec_obj) %>%
    fit(data = training(splits))

wflw_tunedrf <- workflow() %>%
    add_model(
        tuned_forest_spec
    ) %>%
    add_recipe(rec_obj) %>%
    fit(data = training(splits))

wflw_svmrbf <- workflow() %>%
    add_model(
        svm_rbf_spec
    ) %>%
    add_recipe(rec_obj) %>%
    fit(data = training(splits))

wflw_knnspec <- workflow() %>%
    add_model(
        knn_spec
    ) %>%
    add_recipe(rec_obj) %>%
    fit(data = training(splits))  

wflw_xgboost <- workflow() %>%
    add_model(
        xgboost_spec
    ) %>%
    add_recipe(rec_obj) %>%
    fit(data = training(splits))  
```
Create a Modeltime Table
```{r cache= TRUE}
model_tbl <- modeltime_table(
    wflw_rf,
    wflw_tunedrf,
    wflw_svmrbf,
    wflw_knnspec,
    wflw_xgboost
)
model_tbl
```

#Calibrate by client
```{r}
calib_tbl <- model_tbl %>%
    modeltime_calibrate(
      new_data = testing(splits), 
      id       = "client"
    )

calib_tbl
```

Measure Accuracy on validation data
```{r}
#global error
calib_tbl %>% 
    modeltime_accuracy(acc_by_id = FALSE) %>% 
    table_modeltime_accuracy(.interactive = FALSE)
```
```{r}
#local error for each client
calib_tbl %>% 
    modeltime_accuracy(acc_by_id = TRUE) %>% 
    table_modeltime_accuracy(.interactive = FALSE)
```
validate the  Test Data
conf_by_id : produce confidence interval estimates by an ID feature.
#all results
```{r cache=TRUE}
result <- calib_tbl %>%
    modeltime_forecast(
        new_data    = testing(splits),
        actual_data = bind_rows(training(splits), testing(splits)),
        conf_by_id  = TRUE
    ) 
result
```
```{r}
result %>%
    group_by(client) %>%
    filter(client == c( "1", "5", "7","10", "61","100"))%>%
    plot_modeltime_forecast(
        .facet_ncol  = 3,
        .interactive = FALSE,
        .title = "Forecast Plot",
        .line_alpha = 0.6,
        .line_size = 1,
        .y_intercept = 3.0
    )
```

#recipe with zip death
```{r}
rec_obj1 <-
    recipe(shrunk_ae ~ ., data = training(splits)) %>%
    #step_rm(year,month,day)%>%
    step_rm(zip3)%>%
    step_rm( claims , class, shrinkage, ae,smoothed_deaths, ihme_deaths)%>%
    #step_rm(adverse)%>%
    step_mutate(client = droplevels(client)) %>%
    step_timeseries_signature(date) %>%
    step_rm(date)%>%
    step_dummy(all_nominal_predictors(), one_hot = TRUE)%>%
     step_zv(all_predictors()) %>%
    step_normalize(all_predictors(), -all_nominal())

summary(prep(rec_obj1))
bake(prep(rec_obj1),training(splits))
```


# workflow with zip death

```{r cache =TRUE}
wflw_rf1 <- workflow() %>%
    add_model(
        forest_spec
    ) %>%
    add_recipe(rec_obj1) %>%
    fit(data = training(splits))

wflw_tunedrf1 <- workflow() %>%
    add_model(
        tuned_forest_spec
    ) %>%
    add_recipe(rec_obj1) %>%
    fit(data = training(splits))

wflw_svmrbf1 <- workflow() %>%
    add_model(
        svm_rbf_spec
    ) %>%
    add_recipe(rec_obj1) %>%
    fit(data = training(splits))

wflw_knnspec1 <- workflow() %>%
    add_model(
        knn_spec
    ) %>%
    add_recipe(rec_obj1) %>%
    fit(data = training(splits))  

wflw_xgboost1 <- workflow() %>%
    add_model(
        xgboost_spec
    ) %>%
    add_recipe(rec_obj1) %>%
    fit(data = training(splits))  
```
Create a Modeltime Table
```{r}
model_tbl1 <- modeltime_table(
    wflw_rf1,
    wflw_tunedrf1,
    #wflw_neural,
    wflw_svmrbf1,
    #wflw_svmpoly,
    wflw_knnspec1,
    wflw_xgboost1
)
model_tbl1
```

#Calibrate by client
```{r cache=TRUE}
calib_tbl1 <- model_tbl1 %>%
    modeltime_calibrate(
      new_data = testing(splits), 
      id       = "client"
    )

calib_tbl1
```

Measure Accuracy on validation data
```{r}
#global error
calib_tbl1 %>% 
    modeltime_accuracy(acc_by_id = FALSE) %>% 
    table_modeltime_accuracy(.interactive = FALSE)
```
```{r}
#local error for each client
calib_tbl1 %>% 
    modeltime_accuracy(acc_by_id = TRUE) %>% 
    table_modeltime_accuracy(.interactive = FALSE)
```
validate the  Test Data
conf_by_id : produce confidence interval estimates by an ID feature.
#all results
```{r cache=TRUE}
result1 <- calib_tbl1 %>%
    modeltime_forecast(
        new_data    = testing(splits),
        actual_data = bind_rows(training(splits), testing(splits)),
        conf_by_id  = TRUE
    ) 
result1
```
```{r}
result1 %>%
    group_by(client) %>%
    filter(client == c( "1", "5", "7","10", "61","100"))%>%
    plot_modeltime_forecast(
        .facet_ncol  = 3,
        .interactive = FALSE,
        .title = "Forecast Plot",
        .line_alpha = 0.6,
        .line_size = 1,
        .y_intercept = 3.0
    )
```
#recipe without  death
```{r}
rec_obj2 <-
    recipe(shrunk_ae ~ ., data = training(splits)) %>%
    #step_rm(year,month,day)%>%
    step_rm(zip3)%>%
    step_rm( claims , class, shrinkage, ae,smoothed_deaths, ihme_deaths, zip_deaths)%>%
    #step_rm(adverse)%>%
    step_mutate(client = droplevels(client)) %>%
    step_timeseries_signature(date) %>%
    step_rm(date)%>%
    step_dummy(all_nominal_predictors(), one_hot = TRUE)%>%
     step_zv(all_predictors()) %>%
    step_normalize(all_predictors(), -all_nominal())

summary(prep(rec_obj2))
bake(prep(rec_obj2),training(splits))
```
# workflow without  death
```{r cache= TRUE}
wflw_rf2 <- workflow() %>%
    add_model(
        forest_spec
    ) %>%
    add_recipe(rec_obj2) %>%
    fit(data = training(splits))

wflw_tunedrf2 <- workflow() %>%
    add_model(
        tuned_forest_spec
    ) %>%
    add_recipe(rec_obj2) %>%
    fit(data = training(splits))

wflw_svmrbf2 <- workflow() %>%
    add_model(
        svm_rbf_spec
    ) %>%
    add_recipe(rec_obj2) %>%
    fit(data = training(splits))

wflw_knnspec2 <- workflow() %>%
    add_model(
        knn_spec
    ) %>%
    add_recipe(rec_obj2) %>%
    fit(data = training(splits))  

wflw_xgboost2 <- workflow() %>%
    add_model(
        xgboost_spec
    ) %>%
    add_recipe(rec_obj2) %>%
    fit(data = training(splits))  
```
Create a Modeltime Table
```{r cache= TRUE}
model_tbl2 <- modeltime_table(
    wflw_rf2,
    wflw_tunedrf2,
    wflw_svmrbf2,
    wflw_knnspec2,
    wflw_xgboost2
)
model_tbl2
```

#Calibrate by client
```{r}
calib_tbl2 <- model_tbl2 %>%
    modeltime_calibrate(
      new_data = testing(splits), 
      id       = "client"
    )

calib_tbl2
```

Measure Accuracy on validation data
```{r}
#global error
calib_tbl2 %>% 
    modeltime_accuracy(acc_by_id = FALSE) %>% 
    table_modeltime_accuracy(.interactive = FALSE)
```
```{r}
#local error for each client
calib_tbl2 %>% 
    modeltime_accuracy(acc_by_id = TRUE) %>% 
    table_modeltime_accuracy(.interactive = FALSE)
```
validate the  Test Data
conf_by_id : produce confidence interval estimates by an ID feature.
#all results
```{r cache=TRUE}
result2 <- calib_tbl2 %>%
    modeltime_forecast(
        new_data    = testing(splits),
        actual_data = bind_rows(training(splits), testing(splits)),
        conf_by_id  = TRUE
    ) 
result2
```
```{r}
result2 %>%
    group_by(client) %>%
    filter(client == c( "1", "5", "7","10", "61","100"))%>%
    plot_modeltime_forecast(
        .facet_ncol  = 3,
        .interactive = FALSE,
        .title = "Forecast Plot",
        .line_alpha = 0.6,
        .line_size = 1,
        .y_intercept = 3.0
    )
```

```{r}
actual <- clients %>%
  select(date, client, shrunk_ae)
```

#plot sens, spec, accuracy, j_index
#result : with IHME death
#result1: with zip death
#result2: without death

Classify whether the client is adverse or not adverse: shrunk_ae > 2.5.
plot sens, spec,j_index, accuracy
Xgboost has biggest j_index. K-nearest neighbors has good sens, and worst spec while svm has bad sens and good spec.

Calculate the predicted total claim every week and every client for half year.
K-nearest neighbors catch the trend for every week total claim.

Currently, we use the predicting shrunk_ae as predicting result for each model. 
Possible future improvement: 1. use confident interval to find a better predict shrunk_ae 
2. combine different model's results to get final result. 3.Compared the result with weekly death into account, we can add predicted death data as one predictor.

```{r}
threshold = 2.5
```

```{r}
predresult <- result %>%
  select(-.model_desc, -.conf_lo, -.conf_hi, -.key) %>%
  rename(model = .model_id, value = .value, date= .index)%>%
  relocate(model, value, .after = client)%>%
  pivot_wider(names_from = model, values_from =value)%>%
  rename(actual = "NA", rf = "1", rf_tuned = "2", svm_rbd = "3", knn = "4", xgboost = "5" )%>%
  drop_na()%>%
  mutate(obs =  ifelse(actual > threshold  , TRUE, FALSE))%>%
  mutate(rf_pred=  ifelse(rf > threshold ,TRUE, FALSE))%>%
  mutate(rftuned_pred=  ifelse(rf_tuned > threshold ,TRUE, FALSE))%>%
  mutate(svm_pred=  ifelse(svm_rbd > threshold ,TRUE, FALSE))%>%
  mutate(knn_pred=  ifelse(knn > threshold ,TRUE, FALSE))%>%
  mutate(xgboost_pred=  ifelse(xgboost > threshold ,TRUE, FALSE))%>%
  mutate(obs = as.factor(obs), rf_pred = as.factor(rf_pred), rftuned_pred = as.factor(rftuned_pred), 
         svm_pred = as.factor(svm_pred),knn_pred=as.factor(knn_pred), xgboost_pred = as.factor(xgboost_pred))

conf<-predresult%>%
  group_by(date) %>%
  summarize(sens_rf = sens_vec(obs, rf_pred), 
            sens_rftuned = sens_vec(obs, rftuned_pred),
            sens_svm = sens_vec(obs, svm_pred),
            sens_knn = sens_vec(obs, knn_pred),
            sens_xgboost = sens_vec(obs, xgboost_pred),
            spec_rf = spec_vec(obs, rf_pred), 
            spec_rftuned = spec_vec(obs, rftuned_pred),
            spec_svm = spec_vec(obs, svm_pred),
            spec_knn = spec_vec(obs, knn_pred),
            spec_xgboost = spec_vec(obs, xgboost_pred),
            jindex_rf = j_index_vec(obs, rf_pred),
            jindex_rftuned = j_index_vec(obs, rftuned_pred),
            jindex_svm = j_index_vec(obs, svm_pred),
            jindex_knn = j_index_vec(obs, knn_pred),
            jindex_xgboost = j_index_vec(obs, xgboost_pred),
            acc_rf = accuracy_vec(obs, rf_pred), 
            acc_rftuned = accuracy_vec(obs, rftuned_pred),
            acc_svm = accuracy_vec(obs, svm_pred),
            acc_knn = accuracy_vec(obs, knn_pred),
            acc_xgboost = accuracy_vec(obs, xgboost_pred))

conf%>%
  pivot_longer(sens_rf:sens_xgboost, names_to = "metric", values_to = "value")%>%
  ggplot(aes(x = date, y = value, color = metric)) + geom_line()
  
conf%>%
  pivot_longer(spec_rf:spec_xgboost, names_to = "metric", values_to = "value")%>%
  ggplot(aes(x = date, y = value, color = metric)) + geom_line()

conf%>%
  pivot_longer(jindex_rf:jindex_xgboost, names_to = "metric", values_to = "value")%>%
  ggplot(aes(x = date, y = value, color = metric)) + geom_line()

conf%>%
  pivot_longer(acc_rf:acc_xgboost, names_to = "metric", values_to = "value")%>%
  ggplot(aes(x = date, y = value, color = metric)) + geom_line()

```

```{r}
predresult1 <- result1 %>%
  select(-.model_desc, -.conf_lo, -.conf_hi, -.key) %>%
  rename(model = .model_id, value = .value, date= .index)%>%
  relocate(model, value, .after = client)%>%
  pivot_wider(names_from = model, values_from =value)%>%
  rename(actual = "NA", rf = "1", rf_tuned = "2", svm_rbd = "3", knn = "4", xgboost = "5" )%>%
  drop_na()%>%
  mutate(obs =  ifelse(actual > threshold , TRUE, FALSE))%>%
  mutate(rf_pred=  ifelse(rf > threshold ,TRUE, FALSE))%>%
  mutate(rftuned_pred=  ifelse(rf_tuned > threshold ,TRUE, FALSE))%>%
  mutate(svm_pred=  ifelse(svm_rbd > threshold ,TRUE, FALSE))%>%
  mutate(knn_pred=  ifelse(knn > threshold ,TRUE, FALSE))%>%
  mutate(xgboost_pred=  ifelse(xgboost > threshold ,TRUE, FALSE))%>%
  mutate(obs = as.factor(obs), rf_pred = as.factor(rf_pred), rftuned_pred = as.factor(rftuned_pred), 
         svm_pred = as.factor(svm_pred),knn_pred=as.factor(knn_pred), xgboost_pred = as.factor(xgboost_pred))

conf1<-predresult1%>%
  group_by(date) %>%
  summarize(sens_rf = sens_vec(obs, rf_pred), sens_rftuned = sens_vec(obs, rftuned_pred),
            sens_svm = sens_vec(obs, svm_pred),sens_knn = sens_vec(obs, knn_pred),
            sens_xgboost = sens_vec(obs, xgboost_pred),
            spec_rf = spec_vec(obs, rf_pred), spec_rftuned = spec_vec(obs, rftuned_pred),
            spec_svm = spec_vec(obs, svm_pred),spec_knn = spec_vec(obs, knn_pred),
            spec_xgboost = spec_vec(obs, xgboost_pred),
            jindex_rf = j_index_vec(obs, rf_pred), jindex_rftuned = j_index_vec(obs, rftuned_pred),
            jindex_svm = j_index_vec(obs, svm_pred),jindex_knn = j_index_vec(obs, knn_pred),
            jindex_xgboost = j_index_vec(obs, xgboost_pred),
            acc_rf = accuracy_vec(obs, rf_pred), acc_rftuned = accuracy_vec(obs, rftuned_pred),
            acc_svm = accuracy_vec(obs, svm_pred),acc_knn = accuracy_vec(obs, knn_pred),
            acc_xgboost = accuracy_vec(obs, xgboost_pred))

conf1%>%
  pivot_longer(sens_rf:sens_xgboost, names_to = "metric", values_to = "value")%>%
  ggplot(aes(x = date, y = value, color = metric)) + geom_line()
  
conf1%>%
  pivot_longer(spec_rf:spec_xgboost, names_to = "metric", values_to = "value")%>%
  ggplot(aes(x = date, y = value, color = metric)) + geom_line()

conf1%>%
  pivot_longer(jindex_rf:jindex_xgboost, names_to = "metric", values_to = "value")%>%
  ggplot(aes(x = date, y = value, color = metric)) + geom_line()

conf1%>%
  pivot_longer(acc_rf:acc_xgboost, names_to = "metric", values_to = "value")%>%
  ggplot(aes(x = date, y = value, color = metric)) + geom_line()

```
```{r}
predresult2 <- result2 %>%
  select(-.model_desc, -.conf_lo, -.conf_hi, -.key) %>%
  rename(model = .model_id, value = .value, date= .index)%>%
  relocate(model, value, .after = client)%>%
  pivot_wider(names_from = model, values_from =value)%>%
  rename(actual = "NA", rf = "1", rf_tuned = "2", svm_rbd = "3", knn = "4", xgboost = "5" )%>%
  drop_na()%>%
  mutate(obs =  ifelse(actual > threshold , TRUE, FALSE))%>%
  mutate(rf_pred=  ifelse(rf > threshold ,TRUE, FALSE))%>%
  mutate(rftuned_pred=  ifelse(rf_tuned > threshold ,TRUE, FALSE))%>%
  mutate(svm_pred=  ifelse(svm_rbd > threshold ,TRUE, FALSE))%>%
  mutate(knn_pred=  ifelse(knn > threshold ,TRUE, FALSE))%>%
  mutate(xgboost_pred=  ifelse(xgboost > threshold ,TRUE, FALSE))%>%
  mutate(obs = as.factor(obs), rf_pred = as.factor(rf_pred), rftuned_pred = as.factor(rftuned_pred), 
         svm_pred = as.factor(svm_pred),knn_pred=as.factor(knn_pred), xgboost_pred = as.factor(xgboost_pred))

conf2<-predresult2%>%
  group_by(date) %>%
  summarize(sens_rf = sens_vec(obs, rf_pred), sens_rftuned = sens_vec(obs, rftuned_pred),
            sens_svm = sens_vec(obs, svm_pred),sens_knn = sens_vec(obs, knn_pred),
            sens_xgboost = sens_vec(obs, xgboost_pred),
            spec_rf = spec_vec(obs, rf_pred), spec_rftuned = spec_vec(obs, rftuned_pred),
            spec_svm = spec_vec(obs, svm_pred),spec_knn = spec_vec(obs, knn_pred),
            spec_xgboost = spec_vec(obs, xgboost_pred),
            jindex_rf = j_index_vec(obs, rf_pred), jindex_rftuned = j_index_vec(obs, rftuned_pred),
            jindex_svm = j_index_vec(obs, svm_pred),jindex_knn = j_index_vec(obs, knn_pred),
            jindex_xgboost = j_index_vec(obs, xgboost_pred),
            acc_rf = accuracy_vec(obs, rf_pred), acc_rftuned = accuracy_vec(obs, rftuned_pred),
            acc_svm = accuracy_vec(obs, svm_pred),acc_knn = accuracy_vec(obs, knn_pred),
            acc_xgboost = accuracy_vec(obs, xgboost_pred))

conf2%>%
  pivot_longer(sens_rf:sens_xgboost, names_to = "metric", values_to = "value")%>%
  ggplot(aes(x = date, y = value, color = metric)) + geom_line()
  
conf2%>%
  pivot_longer(spec_rf:spec_xgboost, names_to = "metric", values_to = "value")%>%
  ggplot(aes(x = date, y = value, color = metric)) + geom_line()

conf2%>%
  pivot_longer(jindex_rf:jindex_xgboost, names_to = "metric", values_to = "value")%>%
  ggplot(aes(x = date, y = value, color = metric)) + geom_line()

conf2%>%
  pivot_longer(acc_rf:acc_xgboost, names_to = "metric", values_to = "value")%>%
  ggplot(aes(x = date, y = value, color = metric)) + geom_line()

```

What to calculate claim
```{r}
claim <- read_feather("data/processed_data_20_12_23.feather")%>%
  select(date, client, claims, expected, shrinkage,volume)
```
```{r}
predclaim <-
predresult %>%
  inner_join(claim, by = c("date", "client"))%>%
  mutate(rf = rf/shrinkage *(expected /52.18),
         rf_tuned = rf_tuned/shrinkage*(expected /52.18),
         svm_rbd = svm_rbd /shrinkage*(expected /52.18),
         knn = knn/shrinkage*(expected /52.18),
         xgboost= xgboost/shrinkage*(expected / 52.18))%>%
  select(date, client, claims,expected, rf, rf_tuned,svm_rbd,knn,xgboost)

predclaim%>%
  group_by(date)%>%
  summarise(expected = sum(expected)/52.18,
        claims = sum(claims),
          rf =sum(rf) ,
         rf_tuned = sum(rf_tuned),
         svm_rbd = sum(svm_rbd) ,
         knn = sum(knn),
         xgboost= sum(xgboost))%>%
  pivot_longer(expected:xgboost, names_to = "metric", values_to = "value")%>%
  ggplot(aes(x = date, y = value, color = metric)) + geom_line()

predclaim1 <-
predresult1 %>%
  inner_join(claim, by = c("date", "client"))%>%
  mutate(rf = rf/shrinkage *(expected /52.18),
         rf_tuned = rf_tuned/shrinkage*(expected /52.18),
         svm_rbd = svm_rbd /shrinkage*(expected /52.18),
         knn = knn/shrinkage*(expected /52.18),
         xgboost= xgboost/shrinkage*(expected / 52.18))%>%
  select(date, client, claims,expected, rf, rf_tuned,svm_rbd,knn,xgboost)

predclaim1%>%
  group_by(date)%>%
  summarise(expected = sum(expected)/52.18,
        claims = sum(claims),
          rf =sum(rf) ,
         rf_tuned = sum(rf_tuned),
         svm_rbd = sum(svm_rbd) ,
         knn = sum(knn),
         xgboost= sum(xgboost))%>%
  pivot_longer(expected:xgboost, names_to = "metric", values_to = "value")%>%
  ggplot(aes(x = date, y = value, color = metric)) + geom_line()

predclaim2 <-
predresult2 %>%
  inner_join(claim, by = c("date", "client"))%>%
  mutate(rf = rf/shrinkage *(expected /52.18),
         rf_tuned = rf_tuned/shrinkage*(expected /52.18),
         svm_rbd = svm_rbd /shrinkage*(expected /52.18),
         knn = knn/shrinkage*(expected /52.18),
         xgboost= xgboost/shrinkage*(expected / 52.18))%>%
  select(date, client, claims,expected, rf, rf_tuned,svm_rbd,knn,xgboost)

predclaim2%>%
  group_by(date)%>%
  summarise(expected = sum(expected)/52.18,
        claims = sum(claims),
          rf =sum(rf) ,
         rf_tuned = sum(rf_tuned),
         svm_rbd = sum(svm_rbd) ,
         knn = sum(knn),
         xgboost= sum(xgboost))%>%
  pivot_longer(expected:xgboost, names_to = "metric", values_to = "value")%>%
  ggplot(aes(x = date, y = value, color = metric)) + geom_line()
```

```{r}
predclaim%>%
  #mutate(client = as.numeric(client))%>%
  filter(client == c(1:50))%>%
  group_by(client)%>%
  summarise(expected = sum(expected)/52.18,
        claims = sum(claims),
          rf =sum(rf) ,
         rf_tuned = sum(rf_tuned),
         svm_rbd = sum(svm_rbd) ,
         knn = sum(knn),
         xgboost= sum(xgboost))%>%
  pivot_longer(claims:xgboost, names_to = "metric", values_to = "value")%>%
  ggplot(aes(x = client, y = log(value), color = metric)) + geom_point(alpha = 0.5)
```

```




