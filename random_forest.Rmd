### Random forest

## A first attempt!

Load some libraries and necessary data files
```{r}
library(tidyverse)
library(tidymodels)
library(feather)
library(magrittr)
library(skimr)
per <- read_feather("data/simulation_data/all_persons.feather")
```

Compute some summary statistic for each client.
```{r}
clients <-
  per %>%
  group_by(client) %>%
  summarize(
    zip3 = first(zip3),
    size = n(),
    volume = sum(FaceAmt),
    avg_qx = mean(qx),
    avg_age = mean(Age),
    per_male = sum(Sex == "Male") / size,
    per_blue_collar = sum(collar == "Blue") / size,
    expected = sum(qx * FaceAmt),
    actual_2020 = sum(FaceAmt[year == 2020], na.rm = TRUE),
    ae_2020 = actual_2020 / expected,
    adverse = as.factor(ae_2020 > 1.1)
  ) %>%
  relocate(adverse, ae_2020, .after = zip3)
```

We can add some demographic information based on zip3.
```{r}
zip_data <-
  read_feather("data/data.feather") %>%
  mutate(
    density = POP / AREALAND,
    AREALAND = NULL,
    AREA = NULL,
    HU = NULL,
    `Percent adults fully vaccinated against COVID-19 (as of 6/10/21)` = NULL,
    per_lib = NULL,
    per_green = NULL,
    per_other = NULL,
    per_rep = NULL,
    Unemployment_rate_2020 = NULL,
    PCTPOVALL_2019 = NULL,
    `Deaths involving COVID-19` = NULL,
    `Deaths from All Causes` = NULL
  ) %>%
  rename(
    nohs = `less than high school`,
    hs = `high school`,
    unemp = Unemployment_rate_2019,
    hes = `Estimated hesitant`,
    hes_uns = `Estimated hesitant or unsure`,
    str_hes = `Estimated strongly hesitant`,
    svi = `Social Vulnerability Index (SVI)`,
    cvac = `CVAC level of concern for vaccination rollout`,
    income = Median_Household_Income_2019
  )
```
There seems to be some clients with some zip codes that we cannot deal with. These are the ones
```{r}
clients %>%
  anti_join(zip_data, by = "zip3") %>%
  select(zip3)
```
These correspond to the following areas

ZIP3 | Area       |
-----|------------|
969  | Guam, Palau, Federated States of Micronesia, Northern Mariana Islands, Marshall Islands |
093  | Military bases in Iraq and Afghanistan |
732  | Not in use |
872  | Not in use |
004  | Not in use |

We ignore clients with these zip codes.
```{r}
clients %<>%
  inner_join(zip_data, by = "zip3")
```

We now have our full dataset. Behold!
```{r}
skim(clients)
```

## Modelling
We will use a random forest using the tidymodels framework.

We start by creating a recipe. We won't use zip3, client ID, actual claims, or ae_2020 as predictors.
```{r}
ranger_recipe <-
  recipe(adverse ~ ., data = clients) %>%
  update_role(zip3, ae_2020, new_role = "diagnostic") %>%
  step_rm(actual_2020, client)
```

We use the ranger engine for our random forest. We could tune the paramters as well
```{r eval=FALSE}
ranger_spec <-
  rand_forest(trees = 1000) %>%
  set_mode("classification") %>%
  set_engine("ranger")
```

Wrap the recipe and model into a workflow
```{r}
ranger_workflow <-
  workflow() %>%
  add_recipe(ranger_recipe) %>%
  add_model(ranger_spec)
```

Create an initial test-train split
```{r}
init_split <-
  clients %>%
  initial_split(strata = adverse)

clients_test <- testing(init_split)
clients_train <- training(init_split)
```

Train the workflow
```{r}
ranger_trained <-
  ranger_workflow %>%
  fit(clients_train)
```

And we predict
```{r}
predictions <-
  ranger_trained %>%
  predict(clients_test)
```

Compute the confusion matrix
```{r}
predictions %>%
  bind_cols(clients_test %>% select(adverse)) %>%
  conf_mat(adverse, .pred_class)
```
It looks like the the model performs well, but it's basically predicting that all companies will have adverse deaths.

## Subsampling
We will make train the model for more adverse outcomes by using *subsampling*. See e.g. [here](https://www.tidymodels.org/learn/models/sub-sampling/) for a nice introduction.
```{r}
library(themis)
subsample_recipe <-
  ranger_recipe %>%
  step_rose(adverse)
subsample_workflow <-
  ranger_workflow %>%
  update_recipe(subsample_recipe)
val_split <- vfold_cv(clients_train, strata = adverse)

rose_fit <-
  fit_resamples(
    subsample_workflow,
    val_split,
    control = control_resamples(save_pred = TRUE))
  
collect_metrics(rose_fit)
collect_predictions(rose_fit) %>%
  conf_mat(adverse, .pred_class)


ranger_fit <-
  fit_resamples(
    ranger_workflow,
    val_split,
    control = control_resamples(save_pred = TRUE))
  
collect_metrics(ranger_fit)
collect_predictions(ranger_fit) %>%
  conf_mat(adverse, .pred_class)
```





```{r}
set.seed(22361)
# ranger_tune <-
#   tune_grid(
#     ranger_workflow,
#     resamples = stop("add your rsample object"),
#     grid = stop("add number of candidate points"))
```

