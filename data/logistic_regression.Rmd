
```{r}
  library(tidyverse)
  library(feather)
  library(ggplot2)
  library(tidymodels)  
  library(readr)       # for importing data
  library(vip)
  library(lubridate)
```
Currently we use the threshold = 1.1
```{r}
  thres = 1.1
```



Read necessary other data(zip3)
```{r}
otherdata <- read_feather("data.feather")%>%
  mutate(density = POP / AREALAND, AREALAND = NULL)%>%
  select(-Unemployment_rate_2020,-'Deaths involving COVID-19', -'Deaths from All Causes',
         -HU,-AREA)
  
deaths <- read_feather("deaths_zip3.feather")%>%
    mutate(year = year(date), month = month(date), week = week(date))%>%
    group_by(zip3, year, month)%>%
    summarise(deaths = sum(deaths))%>%
    ungroup()
```

Read simulate data(here i just use the first data set)
```{r}
  experience <- readRDS("simulation_data/experience_weekly_1.RDS")
  experience$death[experience$death==2] <- 1
  
  person <-readRDS("simulation_data/person_1.RDS")
```



calculate k-monthly ae value for 2019. for any k, around 10% client's ae is over the threshold 1.1.
```{r}
  k = 1
  test2019 <- experience %>%
    filter(year == 2019)%>%
    left_join(person, by = c("client", "participant"))%>%
    select(-zip3, -industry, -Age, -collar, -Sex, -year)%>%
    mutate(kmonth = (month-1) %/% k)%>%
    group_by(client, participant, kmonth)%>%
    summarise(actual = sum(death) * FaceAmt, expect = sum(qx) * FaceAmt) %>%
    ungroup()%>%
    group_by(client, kmonth)%>%
    summarise(actual = sum(actual), expect = sum(expect)) %>%
    mutate(ae = actual / expect)%>%
    mutate(adverse = ae >1.1)
```
```{r}
  summary(test2019$adverse)
```

calculate the k-month ae value
```{r}
  k = 1
  actual_ae <- experience %>%
    left_join(person, by = c("client", "participant"))%>%
    #mutate(kmonth = (month-1) %/% k)%>%
    group_by(client, participant,zip3,  month, year)%>%
    summarise(actual = sum(death) * FaceAmt, 
              expect = sum(qx) * FaceAmt, 
              FaceAmt = FaceAmt,
              qx = sum(qx),
              sex = Sex,
              age = Age, 
              industry = industry,
              collar = collar) %>%
    ungroup()%>%
    group_by(client, zip3, year, month)%>%
    summarise(actual = sum(actual), 
              expect = sum(expect), 
              size = n(),
              volume = sum(FaceAmt),
              avg_qx = mean(qx),
              avg_age = mean(age),
              per_male = sum(sex == "Male") / size,
              per_blue_collar = sum(collar == "blue") / size,
              ) %>%
    mutate(ae = actual / expect)%>%
    mutate(adverse = ifelse(ae > 1.1, 1, 0),
    adverse = factor(adverse))%>%
    relocate(adverse, ae, .after = zip3)%>%
    ungroup()%>%
    group_by(client)
```

Since covid start spread in 2020, the more and more client's ae values are above the threshood 1.1.
We need to bulid a new model to provide with better expected claim to manage the risk in the future pandemic situation.


```{r}
  summary(actual_ae$adverse[actual_ae$year==2019])
  summary(actual_ae$adverse[actual_ae$year==2020])
  summary(actual_ae$adverse[actual_ae$year==2021])
```
```{r}
  summary(actual_ae$ae[actual_ae$year==2019])
  summary(actual_ae$ae[actual_ae$year==2020])
  summary(actual_ae$ae[actual_ae$year==2021])
```



```{r}
  unique(person$client)#list the clients
  length(unique(person$client))# number of the clients
  glimpse(actual_ae)
  unique(actual_ae$adverse)
  length(unique(actual_ae$adverse))
```

Build model:

#logisitic regression

For logistic regression, we need a target(Y), in our problem, we only have first three month data druing pandemic.

Here I use monthly ae as Y.


    -merge data
```{r}
all_data <- actual_ae %>%
    inner_join(otherdata, by = "zip3")%>%
    mutate(zip3 = factor(zip3)) %>%
    mutate(adverse = ifelse(ae > 1.1, 1, 0),
    adverse = factor(adverse))%>%
    left_join(deaths, by = c("zip3", "year", "month"))%>%
    mutate(rate_deaths = deaths/POP, deaths = NULL) %>%
    mutate(zip3 = factor(zip3))
```

Split data

We have the data for the first three month during pandemic

We use first three month in 2020 data as train set,
the rest month as test data.

```{r}
train <- all_data %>%
  filter(year == 2020, month == c(1,2,3,4))

test <- all_data %>%
  filter(year ==2020, month= !c(1,2,3,4))

test2 <- all_data %>%
  filter(year ==2021)

set.seed(234)
val_set <- validation_split(test, 
                            strata = adverse, 
                            prop = 0.70)
  
val_set
```

```{r}
set.seed(123)
splits <- initial_split(all_data, strata = adverse)
train <- training(splits)
test <- testing(splits)

val_set <- validation_split(test, 
                            strata = adverse, 
                            prop = 0.70)
val_set
```



BUILD THE MODEL

#logistic regression model
```{r}
lr_mod <- 
  logistic_reg(penalty = tune(), mixture = 1) %>% 
  set_engine("glmnet")
```
Create recipe
```{r}
lr_recipe <- 
  recipe(adverse ~ ., data = train) %>%
  update_role(client, zip3, year, new_role = "ID")%>%
  update_role( actual, ae, rate_deaths, new_role = "future")%>%
  update_role('Percent adults fully vaccinated against COVID-19 (as of 6/10/21)', new_role = "future")
  #step_normalize(all_numeric_predictors())
  #update_role(month, new_role = "ID")
  #update_role(per_blue_collar,'less than high school', 'high school','bachelor',  new_role = "ignore")%>%
  #update_role(per_other, per_green, per_lib, new_role = "ignore")%>%
  #update_role('CVAC level of concern for vaccination rollout', new_role = 'ignore')

  #remove_role(actual_ae, old_role = "predictor")
```
```{r}
summary(lr_recipe)
```
Create workflow
```{r}
lr_workflow <- 
  workflow() %>% 
  add_model(lr_mod) %>% 
  add_recipe(lr_recipe)
```
Create the grid for tuning 
```{r}
lr_reg_grid <- tibble(penalty = 10^seq(-4, -1, length.out = 100))

#lr_reg_grid %>% top_n(-5)
```
Train and tune the model
```{r}
lr_res <- 
  lr_workflow %>% 
  tune_grid(val_set,
            grid = lr_reg_grid,
            control = control_grid(save_pred = TRUE),
            metrics = metric_set(roc_auc))
```

```{r}
lr_plot <- 
  lr_res %>% 
  collect_metrics() %>% 
  ggplot(aes(x = penalty, y = mean)) + 
  geom_point() + 
  geom_line() + 
  ylab("Area under the ROC Curve") +
  scale_x_log10(labels = scales::label_number())

lr_plot 
```

```{r}
top_models <-
  lr_res %>% 
  show_best("roc_auc", n = 50) %>% 
  arrange(penalty) 
top_models
```

```{r}
lr_best <- 
  lr_res %>% 
  collect_metrics() %>% 
  arrange(penalty) %>% 
  slice(34)
```

```{r}
lr_auc <- 
  lr_res %>% 
  collect_predictions(parameters = lr_best) %>%
  roc_curve(adverse, .pred_0) %>% 
  mutate(model = "Logistic Regression")

autoplot(lr_auc)

lr_best<- lr_res %>% 
  collect_predictions(parameters = lr_best)
```

Hence we choose penalty = 0.001 as the final penalized logistic regression model

```{r}
lr_mod <- 
  logistic_reg(penalty = 0.001, mixture = 1) %>% 
  set_engine("glmnet")

lr_workflow <- 
  workflow() %>% 
  add_model(lr_mod) %>% 
  add_recipe(lr_recipe)
```
Train the workflow
```{r}
pred_logit_train<-lr_workflow%>%
  fit(data = train)
pred_logit_train %>%
  pull_workflow_fit() %>%
  tidy()
```
And we predict
```{r}
  pred <- predict(pred_logit_train,new_data = test)
#Compute the confusion matrix
pred %>%
  bind_cols(test %>% select(adverse)) %>%
  conf_mat(adverse, .pred_class)
```
It seems all company's adverse is 1. 
(I think it is not that good....need improve!)

(probably we doesn't consider the effect from vaccine/wfh/mask at the late 2020)

```{r}
  pred <- predict(pred_logit_train,new_data = test2)
#Compute the confusion matrix
pred %>%
  bind_cols(test2 %>% select(adverse)) %>%
  conf_mat(adverse, .pred_class)
```


```{r}
lr_test <-lr_recipe%>%
  prep()
pred_logit_train1<-bake(lr_test, new_data = train)

```
```{r}
a<-try_test%>%select(adverse)%>% factor(adverse)
```
```{r}
pred_test<-predict(pred_logit_train, new_data = try_test)
metrics(pred_test,a,predicted)

```

```{r}
last_fit(
  pred_logit_train,
  try_test
) %>%
  collect_metrics()
```


```

































I choose this one because there is detail example online.(not finished)

-LightGBM: 
```{r}
library(data.table)
library(Matrix)
library(dplyr)
library(MLmetrics)
library(lightgbm)
```

-Split data
     -Simple Splitting Based on the Outcome
```{r}
set.seed(3456)
trainIndex <- createDataPartition(try1$adverse, p = .8, 
                                  list = FALSE, 
                                  times = 1)
```
```{r}
Train <- try1[ trainIndex,]
Test <- try1[-trainIndex,]
```
Pre-processing
```{r}
median.impute = function(x){
  x = as.data.frame(x)
  for (i in 1:ncol(x)){
    x[which(x[,i]== -1),i] = NA
  }
  
  x = x %>% mutate_all(~ifelse(is.na(.), median(., na.rm = TRUE), .)) %>% as.data.table()
  return(x)
}

Train = median.impute(Train)
Test  = median.impute(Test)
```
Feature Engineering
```{r}
Test$ae = NA
data = rbind(Train, Test)

data[, fe_amount_NA := rowSums(data == -1, na.rm = T)]
```

Create LGB Dataset
```{r}
varnames = setdiff(colnames(data), c("client", "ae"))
train_sparse = Matrix(as.matrix(data[!is.na(ae), varnames, with=F]), sparse=TRUE)
test_sparse  = Matrix(as.matrix(data[is.na(ae) , varnames, with=F]), sparse=TRUE)

y_train  = data[!is.na(ae),ae]
test_ids = data[is.na(ae) ,client]

lgb.train = lgb.Dataset(data=train_sparse, label=y_train)

categoricals.vec = colnames(train)[c(grep("cat",colnames(train)))]
```

Setting up LGBM Parameters
```{r}

lgb.grid = list(objective = "binary",
                metric = "auc",
                min_sum_hessian_in_leaf = 1,
                feature_fraction = 0.7,
                bagging_fraction = 0.7,
                bagging_freq = 5,
                min_data = 100,
                max_bin = 50,
                lambda_l1 = 8,
                lambda_l2 = 1.3,
                min_data_in_bin=100,
                min_gain_to_split = 10,
                min_data_in_leaf = 30,
                is_unbalance = TRUE)
```

Setting up Gini Eval Function
```{r}
# Gini for Lgb
lgb.normalizedgini = function(preds, dtrain){
  actual = getinfo(dtrain, "label")
  score  = NormalizedGini(preds,actual)
  return(list(name = "gini", value = score, higher_better = TRUE))
}
```
Train Final Model
```{r}
best.iter = 525
# Train final model
lgb.model = lgb.train(params = lgb.grid, data = lgb.train, learning_rate = 0.02,
                      num_leaves = 25, num_threads = 2 , nrounds = best.iter,
                      eval_freq = 20, eval = lgb.normalizedgini,
                      categorical_feature = categoricals.vec)
```

```{r}
preds = data.table(id=test_ids, target=predict(lgb.model,test_sparse))
colnames(preds)[1] = "id"
fwrite(preds, "submission.csv")
```













