# Random forests

## Data business

Load some libraries and necessary data files
```{r}
library(tidyverse)
library(tidymodels)
library(feather)
library(magrittr)
library(skimr)
library(vip)
per <- read_feather("data/simulation_data/all_persons.feather")
```

Compute some summary statistic for each client.
```{r}
clients <-
  per %>%
  group_by(client) %>%
  summarize(
    zip3 = first(zip3),
    size = n(),
    volume = sum(FaceAmt),
    avg_qx = mean(qx),
    avg_age = mean(Age),
    per_male = sum(Sex == "Male") / size,
    per_blue_collar = sum(collar == "blue") / size,
    expected = sum(qx * FaceAmt),
    actual_2020 = sum(FaceAmt[year == 2020], na.rm = TRUE),
    ae_2020 = actual_2020 / expected,
    adverse = as_factor(if_else(ae_2020 > 3, "ae > 3", "ae < 3"))
  ) %>%
  relocate(adverse, ae_2020, .after = zip3) %>%
  mutate(adverse = fct_relevel(adverse, c("ae > 3", "ae < 3")))
```

We can add some demographic information based on zip3.
```{r}
zip_data <-
  read_feather("data/data.feather") %>%
  mutate(
    density = POP / AREALAND,
    AREALAND = NULL,
    AREA = NULL,
    HU = NULL,
    vaccinated = NULL,
    per_lib = NULL,
    per_green = NULL,
    per_other = NULL,
    per_rep = NULL,
    unempl_2020 = NULL,
    deaths_covid = NULL,
    deaths_all = NULL
  ) %>%
  rename(
    unemp = unempl_2019,
    hes_uns = hes_unsure,
    str_hes = strong_hes,
    income = Median_Household_Income_2019
  )
```
There seems to be some clients with some zip codes that we cannot deal with. These are the ones
```{r}
clients %>%
  anti_join(zip_data, by = "zip3") %>%
  select(zip3)
```
These correspond to the following areas

ZIP3 | Area       |
-----|------------|
969  | Guam, Palau, Federated States of Micronesia, Northern Mariana Islands, Marshall Islands |
093  | Military bases in Iraq and Afghanistan |
732  | Not in use |
872  | Not in use |
004  | Not in use |
202  | Washington DC, Government 1 |

We ignore clients with these zip codes. There are also two clients in DC for which we're missing election data. We will ignore those as well.
```{r}
clients %<>%
  inner_join(zip_data, by = "zip3") %>%
  drop_na()
```

We now have our full dataset. Behold!
```{r}
skim(clients)
```

# RBF Support Vector Machine model 

# Engine
```{r}
svm_rbf_spec <-
  svm_rbf() %>%
  set_engine("kernlab") %>%
  set_mode("classification")
```

# Recipe 
```{r}
svm_rbf_recipe <- 
  recipe(formula = adverse ~ ., data = clients) %>% 
  step_rm(client, zip3, ae_2020, actual_2020 ) %>%
  step_zv(all_predictors()) %>% # remove zero variance columns (in our case it will remove per collar)
  step_normalize(all_predictors(), -all_nominal()) 
```

# Workflow 
```{r}
svm_rbf_workflow <- 
  workflow() %>%
  add_model(svm_rbf_spec) %>% 
  add_recipe(svm_rbf_recipe)
```

# Feed data (train the model)
```{r}
set.seed(4751)
svm_rbf_split <- initial_split(clients, prop=0.8, strata= adverse) # it will split data in a way why keeping the proportion of adverse the same (splitting based on the outcome)

# here it directly split then use test and find accuracy, get summary results using collect_metrics
svm_rbf_fit <- svm_rbf_workflow %>%
  last_fit(svm_rbf_split, metrics=metric_set(sens, spec, ppv, npv, bal_accuracy, detection_prevalence))
```

# Getting results 
```{r}
svm_rbf_fit %>% 
  collect_metrics()
```

# Penalized SVM RBF Model 2 
```{r}
svm_rbf_2_spec <-
  svm_rbf(cost=tune()) %>%
  set_engine("kernlab") %>%
  set_mode("classification")

svm_rbf_2_spec %>% 
  translate() 
mixture()
```

```{r}
svm_rbf_2_workflow <- 
  workflow() %>%
  add_model(svm_rbf_2_spec) %>% 
  add_recipe(svm_rbf_recipe)
```

# we need to choose the penalty (furter split training into training and validation or do cross validation )
```{r}
svm_rbf_val <- validation_split(training(svm_rbf_split))
svm_rbf_val
```

# Now we want to tune
```{r}
svm_rbf_penalty <- grid_regular(cost(), levels=100)
svm_rbf_2_tune <-
  svm_rbf_2_workflow %>%
  tune_grid(svm_rbf_val,
            grid = svm_rbf_penalty,
            metrics = metric_set(sens, spec, ppv, npv, bal_accuracy))
svm_rbf_2_tune
```

```{r}
svm_rbf_2_tune %>%
  collect_metrics() %>%
  filter(.metric == "sens") %>%
  ggplot(aes(x = cost, y = mean)) + geom_line() + scale_x_log10() + geom_vline(xintercept = 4.350593e+00)

autoplot(svm_rbf_2_tune)
```

```{r}
svm_rbf_2_tune %>%
  collect_metrics()

svm_rbf_2_tune %>%
  collect_metrics() %>%
  filter(cost <= 32) %>%
  filter(.metric == "sens") %>%
  arrange(desc(mean))

```

# We have found the best tuning parameter and now we have to use it
```{r}
svm_rbf_2_tuned_workflow <- svm_rbf_2_workflow %>% 
  finalize_workflow(parameters=list(cost=4.350593e+00))

svm_rbf_2_tuned_fit <- svm_rbf_2_tuned_workflow %>%
  last_fit(svm_rbf_split, metrics=metric_set(sens, spec, ppv, npv, bal_accuracy))
```

# Comparing the firts model with the penalysed model (with the best tuning paramter)
```{r}
collect_metrics(svm_rbf_2_tuned_fit)
collect_metrics(svm_rbf_fit)
```

# For each of the client in our test set, let's have a look at the predicted target variable and the actual adverse variable.  
```{r}
svm_rbf_2_tuned_fit %>% 
  collect_predictions()
```



# Polynomial Support Vector Machine model 

# Engine
```{r}
svm_poly_spec <-
  svm_poly() %>%
  set_engine("kernlab") %>%
  set_mode("classification")
```

# Recipe 
```{r}
svm_poly_recipe <- 
  recipe(formula = adverse ~ ., data = clients) %>% 
  step_rm(client, zip3, ae_2020, actual_2020 ) %>%
  step_zv(all_predictors()) %>% # remove zero variance columns (in our case it will remove per collar)
  step_normalize(all_predictors(), -all_nominal()) 
```

# Workflow 
```{r}
svm_poly_workflow <- 
  workflow() %>%
  add_model(svm_poly_spec) %>% 
  add_recipe(svm_poly_recipe)
```

# Feed data (train the model)
```{r}
set.seed(4751)
svm_poly_split <- initial_split(clients, prop=0.8, strata= adverse) # it will split data in a way why keeping the proportion of adverse the same (splitting based on the outcome)

# here it directly split then use test and find accuracy, get summary results using collect_metrics
svm_poly_fit <- svm_poly_workflow %>%
  last_fit(svm_poly_split, metrics=metric_set(sens, spec, ppv, npv, bal_accuracy, detection_prevalence))
```

# Getting results 
```{r}
svm_poly_fit %>% 
  collect_metrics()
```


